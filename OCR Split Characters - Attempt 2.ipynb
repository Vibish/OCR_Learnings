{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images created for 0\n",
      "Training images created for 1\n"
     ]
    }
   ],
   "source": [
    "#Build training images\n",
    "path = 'CharSplit/'\n",
    "#Paste the images onto a constant background and blend the images    \n",
    "def setImage(image):\n",
    "    image = imutils.resize(image,height=20)\n",
    "    gray_masked = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, im_bw) = cv2.threshold(gray_masked, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #print(im_bw.shape)\n",
    "    #Draw a white canvas\n",
    "    white_img = np.zeros((40,40), np.uint8)\n",
    "    white_img[:,:] = (255)\n",
    "    #Paste the image onto the white canvas\n",
    "    x_offset=y_offset=1\n",
    "    white_img[y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = im_bw\n",
    "    return white_img\n",
    "\n",
    "for filename in os.listdir(path+'0/'):\n",
    "    org_img = cv2.imread(path+'0/'+filename)    \n",
    "    #r = 15.0 / org_img.shape[1]\n",
    "    #dim = (15, int(org_img.shape[0] * r))\n",
    "    # perform the actual resizing of the image and show it\n",
    "    #resized = cv2.resize(org_img, dim, interpolation = cv2.INTER_AREA) \n",
    "    cv2.imwrite('CharSplitTrain/0/'+filename,setImage(org_img))\n",
    "    \n",
    "    \n",
    "print('Training images created for 0')\n",
    "\n",
    "for filename in os.listdir(path+'1/'):\n",
    "    org_img = cv2.imread(path+'1/'+filename)    \n",
    "    #r = 15.0 / org_img.shape[1]\n",
    "    #dim = (15, int(org_img.shape[0] * r))\n",
    "    # perform the actual resizing of the image and show it\n",
    "    #resized = cv2.resize(org_img, dim, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite('CharSplitTrain/1/'+filename,setImage(org_img))   \n",
    "    \n",
    "print('Training images created for 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files = 366\n",
      "loaded from 0\n",
      "loaded from 1\n"
     ]
    }
   ],
   "source": [
    "noOfFiles0 = len([name for name in os.listdir('CharSplitTrain/0/')])\n",
    "noOfFiles1 = len([name for name in os.listdir('CharSplitTrain/1/')])\n",
    "noOfFiles = noOfFiles0 + noOfFiles1\n",
    "\n",
    "print('Total number of files = '+str(noOfFiles))\n",
    "reshaped = np.empty([noOfFiles,1600])\n",
    "Y = np.empty([noOfFiles,1])\n",
    "\n",
    "\n",
    "j=0\n",
    "for filename in os.listdir('CharSplitTrain/0/'):    \n",
    "    img = cv2.imread('CharSplitTrain/0/'+filename,0)\n",
    "    reshaped[j]=img.reshape(1,1600)\n",
    "    Y[j] = 0\n",
    "    j=j+1\n",
    "print('loaded from 0')\n",
    "for filename in os.listdir('CharSplitTrain/1/'):\n",
    "    img = cv2.imread('CharSplitTrain/1/'+filename,0)\n",
    "    reshaped[j]=img.reshape(1,1600)\n",
    "    Y[j] = 1\n",
    "    j=j+1\n",
    "print('loaded from 1')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.\n",
      "  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.\n",
      "  0.  0.]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.85      0.87        62\n",
      "        1.0       0.72      0.77      0.74        30\n",
      "\n",
      "avg / total       0.83      0.83      0.83        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = np.ravel(Y)\n",
    "(X_Train,X_Test,Y_Train,Y_Test) = train_test_split(reshaped,Y)\n",
    "model2 = LogisticRegression(C=1e5)\n",
    "model2.fit(X_Train, Y_Train)\n",
    "predicted = model2.predict(X_Test)\n",
    "print(predicted)\n",
    "#probs = model2.predict_proba(X_Test)\n",
    "#print (probs)\n",
    "print (metrics.classification_report(Y_Test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(model2,open('CharSplit.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/Desktop/Data Analytics/OCR/Background\n"
     ]
    }
   ],
   "source": [
    "cd Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from skimage import transform as tf\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "bgimage = Image.open('MasterBG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create 500 random background images of size 25 * 20\n",
    "for i in range(500):\n",
    "    x_rand = random.randint(1,1306)\n",
    "    y_rand = random.randint(1,81)\n",
    "    sampleBG = bgimage.crop((x_rand,y_rand,x_rand+20,y_rand+25))\n",
    "    #cd 'C:\\Users\\kunjithapatham.s\\Desktop\\Data Analytics\\OCR\\Background\\BGList'\n",
    "    filename = 'BGList/BG'+str(i)+'.png'\n",
    "    #print(filename)\n",
    "    sampleBG.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples created...\n"
     ]
    }
   ],
   "source": [
    "#Write alphabets with the font type arialbd on each of the 500 generated background images\n",
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "fnt = ImageFont.truetype('arialbd.ttf', 20)\n",
    "tcolor = (255,255,255)\n",
    "text_pos = (0,0)\n",
    "for i in range(500):\n",
    "    filename = 'BGList/BG'+str(i)+'.png'\n",
    "    #print(filename)    \n",
    "    for alpha in alphanum:        \n",
    "        bgimage = Image.open(filename)       \n",
    "        draw  = ImageDraw.Draw(bgimage)\n",
    "        #draw.text(text_pos,alpha,tcolor,font=fnt)\n",
    "        draw.text(text_pos,alpha,font=fnt)\n",
    "        bgimage.save('samples/'+alpha+'_BG'+str(i)+'.png')\n",
    "        \n",
    "print('samples created...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fnt = ImageFont.truetype('arialbd.ttf', 20)\n",
    "#tcolor = (255,255,255)\n",
    "#text_pos = (0,0)\n",
    "\n",
    "#filename = 'BGList/BG'+str(1)+'.png'\n",
    "#bgimage = Image.open(filename)       \n",
    "#draw  = ImageDraw.Draw(bgimage)\n",
    "#draw.text(text_pos,'Y',font=fnt)\n",
    "#bgimage.save('samples/'+'A'+'_BG'+str(i)+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples updated with skewed images\n"
     ]
    }
   ],
   "source": [
    "#Skew some images (some random 300 image for each character)\n",
    "\n",
    "\n",
    "\n",
    "shearValues = [-0.3,-0.2,-0.1,0.1,0.2,0.3]\n",
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "for alpha in alphanum: \n",
    "    for i in range(100):\n",
    "        randomFileNum = random.randint(0,499)\n",
    "        randomFileName = 'samples/'+alpha+'_BG'+str(randomFileNum)+'.png'\n",
    "        image = io.imread(randomFileName)\n",
    "        afine_tf = tf.AffineTransform(shear=shearValues[random.randint(0,5)])\n",
    "        modified = tf.warp(image,afine_tf)\n",
    "        scipy.misc.imsave(randomFileName, modified)\n",
    "print('samples updated with skewed images')\n",
    "        #scipy.misc.toimage(modified, cmin=0.0, cmax=...).save(randomFileName)\n",
    "        #modified.save('samples/'+alpha+'_BG'+str(randomFileNum)+'.png')\n",
    "        \n",
    "# Load the image as a matrix\n",
    "#image = io.imread(\"samples/0_BG4.png\")\n",
    "\n",
    "# Create Afine transform\n",
    "#afine_tf = tf.AffineTransform(shear=0.2)\n",
    "\n",
    "# Apply transform to image data\n",
    "#modified = tf.warp(image, afine_tf)\n",
    "\n",
    "# Display the result\n",
    "#io.imshow(modified)\n",
    "#io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch = image.shape   \n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = image\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "                for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "                for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Induce Noise\n",
    "\n",
    "\n",
    "noise_types = [\"gauss\",\"s&p\",\"poisson\",\"speckle\"]\n",
    "\n",
    "#for filename in os.listdir('samples/'):\n",
    "#    #print(filename)\n",
    "#    i = random.randint(0,3)\n",
    "#    noise_type = noise_types[i]\n",
    "#    #print(noise_type)\n",
    "#    image = cv2.imread('samples/'+filename,1)\n",
    "#    image = noisy(noise_type,image)    \n",
    "#    #print(image)\n",
    "#    #gray_image = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "#    cv2.imwrite('samples/'+filename,image)\n",
    "    \n",
    "for filename in os.listdir('samples/'):\n",
    "    #print(filename)\n",
    "    #i = random.randint(0,3)\n",
    "    noise_type = 'speckle' #noise_types[i]    \n",
    "    image = cv2.imread('samples/'+filename,1)\n",
    "    image = noisy(noise_type,image)        \n",
    "    cv2.imwrite('samples/'+filename,image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Magnitude Spectrum\n",
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "#def applyMagnitudeSpectrum(img):\n",
    "    #dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    #dft_shift = np.fft.fftshift(dft)\n",
    "    #rows, cols,value = img.shape\n",
    "    #crow,ccol = rows/2 , cols/2\n",
    "\n",
    "    # create a mask first, center square is 1, remaining all zeros\n",
    "    #mask = np.zeros((rows,cols,2),np.uint8)\n",
    "    #mask[crow-30:crow+30, ccol-30:ccol+30] = 1\n",
    "\n",
    "    # apply mask and inverse DFT\n",
    "    #fshift = dft_shift*mask\n",
    "    #f_ishift = np.fft.ifftshift(fshift)\n",
    "    #img_back = cv2.idft(f_ishift)\n",
    "    #img_b#3ack = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    "  \n",
    "            \n",
    "for alpha in alphanum: \n",
    "    for i in range(200):\n",
    "        randomFileNum = random.randint(0,499)\n",
    "        randomFileName = 'samples/'+alpha+'_BG'+str(randomFileNum)+'.png'\n",
    "        image = io.imread(randomFileName)\n",
    "        image = cv2.blur(image,(5,5))\n",
    "        #image = applyMagnitudeSpectrum(image)\n",
    "        cv2.imwrite('samples/'+filename,image)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert all the images to black and white using PIL\n",
    "for filename in os.listdir('samples/'):\n",
    "    image_file = Image.open('samples/'+filename)\n",
    "    image_file = image_file.convert('1')\n",
    "    image_file.save('samplesBW/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping Complete\n",
      "Starting to segregate Training and Validation sets\n",
      "Segregation Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "reshaped = np.empty([0,500])\n",
    "Y = np.chararray([(len(alphanum))*499,1]) \n",
    "j=0\n",
    "for alpha in alphanum:\n",
    "    for i in range(499):\n",
    "        filename = 'samples/'+alpha+'_BG'+str(i)+'.png'\n",
    "        image = io.imread(filename,'1')\n",
    "        reshaped = np.concatenate([reshaped,image.reshape(1,500)])\n",
    "        Y[j] = alpha\n",
    "        j = j+1\n",
    "\n",
    "print('Reshaping Complete')\n",
    "print('Starting to segregate Training and Validation sets')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(reshaped,Y)\n",
    "\n",
    "\n",
    "print('Segregation Completed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to feature scaling\n",
      "Feature Scaling Completed\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:904: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n",
      "Now start predicting for the validation set\n",
      "Predictions done\n",
      "evaluate the results\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       b'0'       0.87      0.90      0.88       124\n",
      "       b'1'       0.97      0.96      0.97       120\n",
      "       b'2'       0.93      0.92      0.93       130\n",
      "       b'3'       0.91      0.95      0.93       113\n",
      "       b'4'       0.94      0.94      0.94       115\n",
      "       b'5'       0.95      0.95      0.95       128\n",
      "       b'6'       0.93      0.89      0.91       125\n",
      "       b'7'       0.97      0.96      0.96       115\n",
      "       b'8'       0.88      0.92      0.90       131\n",
      "       b'9'       0.92      0.89      0.90       123\n",
      "       b'A'       0.92      0.94      0.93       126\n",
      "       b'B'       0.94      0.97      0.96       115\n",
      "       b'C'       0.97      0.91      0.94       142\n",
      "       b'D'       0.89      0.95      0.92       108\n",
      "       b'E'       0.98      0.99      0.98       140\n",
      "       b'F'       0.99      0.95      0.97       145\n",
      "       b'G'       0.94      0.92      0.93       125\n",
      "       b'H'       0.99      0.98      0.99       123\n",
      "       b'I'       0.98      0.94      0.96       132\n",
      "       b'J'       0.94      0.97      0.95       125\n",
      "       b'K'       0.94      0.95      0.95       118\n",
      "       b'L'       0.94      0.97      0.95       131\n",
      "       b'M'       0.97      0.97      0.97       120\n",
      "       b'N'       0.96      0.92      0.94       143\n",
      "       b'O'       0.89      0.91      0.90       121\n",
      "       b'P'       0.93      0.94      0.94       133\n",
      "       b'Q'       0.93      0.94      0.93       126\n",
      "       b'R'       0.89      0.91      0.90       109\n",
      "       b'S'       0.96      0.93      0.95       139\n",
      "       b'T'       0.99      0.97      0.98       121\n",
      "       b'U'       0.94      0.94      0.94       127\n",
      "       b'V'       0.86      0.91      0.89       102\n",
      "       b'W'       0.99      0.95      0.97       128\n",
      "       b'X'       0.90      0.93      0.91       121\n",
      "       b'Y'       0.94      0.92      0.93       128\n",
      "       b'Z'       0.97      0.99      0.98       119\n",
      "\n",
      "avg / total       0.94      0.94      0.94      4491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('starting to feature scaling')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_Train)\n",
    "X_Train = scaler.transform(X_Train)\n",
    "X_Test = scaler.transform(X_Test)\n",
    "\n",
    "print('Feature Scaling Completed')\n",
    "print('Start training')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X_Train,Y_Train)\n",
    "\n",
    "\n",
    "print('Training done...')\n",
    "print('Now start predicting for the validation set')\n",
    "predictions = mlp.predict(X_Test)\n",
    "\n",
    "print('Predictions done')\n",
    "print('evaluate the results')\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(Y_Test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Test with actual images from pancard\n",
    "#Convert all the images to black and white\n",
    "for filename in os.listdir('Test/'):\n",
    "    image_file = Image.open('Test/'+filename)\n",
    "    image_file = image_file.convert('1')\n",
    "    image_file.save('TestBW/'+filename)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pannumber = ['A','W','S','P','K','5','9','6','7','E']\n",
    "reshaped1 = np.empty([0,500])\n",
    "Y1=np.chararray([len(pannumber),1])\n",
    "j=0\n",
    "for alpha in pannumber:\n",
    "    filename = 'TestBW/'+alpha+'.PNG'\n",
    "    image = io.imread(filename,'1')\n",
    "    image = cv2.resize(image, (25,20)) \n",
    "    reshaped1 = np.concatenate([reshaped1,image.reshape(1,500)])\n",
    "    Y1[j] = alpha\n",
    "    j = j+1\n",
    "\n",
    "print(reshaped1.shape)\n",
    "print(Y1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       b'1'       0.00      0.00      0.00         0\n",
      "       b'2'       0.00      0.00      0.00         0\n",
      "       b'5'       0.00      0.00      0.00         1\n",
      "       b'6'       0.00      0.00      0.00         1\n",
      "       b'7'       0.33      1.00      0.50         1\n",
      "       b'9'       0.00      0.00      0.00         1\n",
      "       b'A'       0.00      0.00      0.00         1\n",
      "       b'E'       0.00      0.00      0.00         1\n",
      "       b'J'       0.00      0.00      0.00         0\n",
      "       b'K'       0.00      0.00      0.00         1\n",
      "       b'P'       0.00      0.00      0.00         1\n",
      "       b'S'       0.00      0.00      0.00         1\n",
      "       b'T'       0.00      0.00      0.00         0\n",
      "       b'W'       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.03      0.10      0.05        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X1_Test = scaler.transform(reshaped1)\n",
    "predictions = mlp.predict(X1_Test)\n",
    "print(classification_report(Y1,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

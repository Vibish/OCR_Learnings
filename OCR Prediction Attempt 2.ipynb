{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detectLetters(image,kernelSize,rtvMode,approx):\n",
    "    boundRect = [None]\n",
    "    #image = cv2.imread(inputFilename)\n",
    "    \n",
    " \n",
    "    # convert the image to grayscale, blur it, and find edges\n",
    "    # in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "    # show the original image and the edge detected image\n",
    "    cv2.imwrite('originals/dltme1.png',edged)\n",
    "    print (\"STEP 1: Edge Detection\")\n",
    "\n",
    "    #Binary Dialation\n",
    "    kernelSize = (17,3)\n",
    "    element = cv2.getStructuringElement (cv2.MORPH_RECT, kernelSize )\n",
    "    img_threshold = cv2.morphologyEx(edged,cv2.MORPH_CLOSE,element)\n",
    "    cv2.imwrite('originals/dltme2.png',img_threshold)\n",
    "    print('Binary dialation done...')\n",
    "    \n",
    "    #Find Contours\n",
    "    im2,contours,hierarchy = cv2.findContours(img_threshold,rtvMode,approx)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    for i in range(0,len(contours)):\n",
    "        if len(contours[i])>100:            \n",
    "            contours_poly[i]=(cv2.approxPolyDP(contours[i], 3, True))            \n",
    "            x,y,w,h = cv2.boundingRect(contours_poly[i])            \n",
    "            if w>h:\n",
    "                temp = x,y,w,h\n",
    "                boundRect.append(temp)\n",
    "    return boundRect\n",
    "\n",
    "def convertToBW(image):\n",
    "    gray_masked = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, im_bw) = cv2.threshold(gray_masked, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return im_bw\n",
    "\n",
    "def setImage(image):   \n",
    "    #print('Before Resizing = ',image.shape)\n",
    "    (height,width) = image.shape   \n",
    "    if height > 20:    \n",
    "        if width < 20 :\n",
    "            #crop\n",
    "            image = image[1:30,:]\n",
    "        else:            \n",
    "            #print(image.shape)\n",
    "            image = imutils.resize(image,height=20)\n",
    "    (height,width) = image.shape\n",
    "    if width > 20:\n",
    "        if height < 10:\n",
    "            #Crop\n",
    "            image = image[:,1:30]\n",
    "        else:\n",
    "            image = imutils.resize(image,width=20)           \n",
    "        \n",
    "    #print('After Resizing = ',image.shape)\n",
    "    #image = imutils.resize(image, width=20)\n",
    "    #Draw a white canvas\n",
    "    white_img = np.zeros((40,40), np.uint8)\n",
    "    white_img[:,:] = (255)\n",
    "    #Paste the image onto the white canvas\n",
    "    x_offset=y_offset=1    \n",
    "    white_img[y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = image\n",
    "    return white_img\n",
    "\n",
    "def extractTextArea(inputFile,kernelSize,rtvMode,approx):\n",
    "    j=0\n",
    "    #implementation    \n",
    "    img = cv2.imread(inputFile)\n",
    "    ratio = img.shape[0] / 500.0\n",
    "    orig = img.copy()\n",
    "    img = imutils.resize(img, height = 500)\n",
    "    letterBBoxes=detectLetters(img,kernelSize,rtvMode,approx)\n",
    "    textArea_Count = 0\n",
    "    for i in range(0,len(letterBBoxes)-1):\n",
    "        if letterBBoxes[i] != None:   \n",
    "            textArea_Count = textArea_Count + 1\n",
    "            temp = letterBBoxes[i]\n",
    "            cv2.rectangle(orig,(temp[0],temp[1]),(temp[0]+temp[2],temp[1]+temp[3]),(0,255,0),3)\n",
    "            crop_image = img[temp[1]:temp[1]+temp[3], temp[0]:temp[0]+temp[2]]\n",
    "            cv2.imwrite('dltme/textArea'+str(textArea_Count)+'.png',crop_image)\n",
    "            bw_img = convertToBW(crop_image)\n",
    "           \n",
    "            (height1,width1) = bw_img.shape\n",
    "            init_column = 0\n",
    "            end_column = 5\n",
    "            i=0\n",
    "            char_list = []\n",
    "            \n",
    "            \n",
    "            while init_column + end_column + i < width1:    \n",
    "                sumValue = bw_img[:,init_column+end_column+i].sum()                \n",
    "                if (sumValue / 255) == height1: \n",
    "                    \n",
    "                    char_image = bw_img[:,init_column:init_column+end_column+i]\n",
    "                    init_column = init_column + end_column+i+1\n",
    "                    i=0                    \n",
    "                    #j=j+1\n",
    "                    char_list.append(char_image)                \n",
    "                i=i+1\n",
    "            if (i>5):\n",
    "                char_image = bw_img[:,init_column:init_column+end_column+i-1]\n",
    "                char_list.append(char_image) \n",
    "            \n",
    "            print(len(char_list))\n",
    "            for entry in char_list:\n",
    "                #temp_img = cv2.blur(setImage(entry),(2,2))\n",
    "                temp_img = cv2.blur(setImage(entry),(2,2))\n",
    "                cv2.imwrite('dltme/dltme_'+str(j)+'.png',temp_img);j=j+1                \n",
    "                prediction = loaded_model.predict(temp_img.reshape(1,1600))\n",
    "                print(str(prediction))\n",
    "                #image = cv2.blur(image,(2,2))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n",
      "Binary dialation done...\n",
      "7\n",
      "[b'K']\n",
      "[b'N']\n",
      "[b'K']\n",
      "[b'K']\n",
      "[b'I']\n",
      "[b'K']\n",
      "[b'N']\n",
      "6\n",
      "[b'7']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n",
      "10\n",
      "[b'H']\n",
      "[b'N']\n",
      "[b'Z']\n",
      "[b'P']\n",
      "[b'M']\n",
      "[b'Z']\n",
      "[b'5']\n",
      "[b'D']\n",
      "[b'1']\n",
      "[b'F']\n",
      "22\n",
      "[b'1']\n",
      "[b'K']\n",
      "[b'I']\n",
      "[b'N']\n",
      "[b'K']\n",
      "[b'1']\n",
      "[b'K']\n",
      "[b'1']\n",
      "[b'I']\n",
      "[b'T']\n",
      "[b'I']\n",
      "[b'1']\n",
      "[b'7']\n",
      "[b'K']\n",
      "[b'K']\n",
      "[b'I']\n",
      "[b'1']\n",
      "[b'K']\n",
      "[b'N']\n",
      "[b'K']\n",
      "[b'K']\n",
      "[b'I']\n",
      "3\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n",
      "1\n",
      "[b'1']\n",
      "1\n",
      "[b'M']\n",
      "2\n",
      "[b'E']\n",
      "[b'1']\n",
      "1\n",
      "[b'1']\n",
      "9\n",
      "[b'1']\n",
      "[b'A']\n",
      "[b'I']\n",
      "[b'7']\n",
      "[b'F']\n",
      "[b'1']\n",
      "[b'T']\n",
      "[b'P']\n",
      "[b'P']\n",
      "9\n",
      "[b'D']\n",
      "[b'U']\n",
      "[b'R']\n",
      "[b'A']\n",
      "[b'I']\n",
      "[b'S']\n",
      "[b'A']\n",
      "[b'M']\n",
      "[b'T']\n",
      "12\n",
      "[b'G']\n",
      "[b'1']\n",
      "[b'M']\n",
      "[b'A']\n",
      "[b'N']\n",
      "[b'I']\n",
      "[b'K']\n",
      "[b'A']\n",
      "[b'N']\n",
      "[b'G']\n",
      "[b'A']\n",
      "[b'N']\n",
      "1\n",
      "[b'O']\n",
      "12\n",
      "[b'I']\n",
      "[b'N']\n",
      "[b'I']\n",
      "[b'D']\n",
      "[b'M']\n",
      "[b'E']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'E']\n",
      "[b'1']\n",
      "[b'E']\n",
      "[b'N']\n",
      "9\n",
      "[b'D']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'O']\n",
      "[b'7']\n",
      "[b'T']\n",
      "[b'N']\n",
      "[b'D']\n",
      "[b'U']\n",
      "1\n",
      "[b'1']\n",
      "1\n",
      "[b'1']\n",
      "1\n",
      "[b'1']\n",
      "1\n",
      "[b'1']\n",
      "5\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n",
      "[b'1']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "loaded_model = pickle.load(open('Model output/AlphabetRecognition.sav', 'rb'))\n",
    "kernelSize = (17,3)\n",
    "\n",
    "#extractTextArea('originals/Pancard.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "extractTextArea('originals/Pancard_Web_1_1.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/Desktop/Data Analytics/OCR/Background\n"
     ]
    }
   ],
   "source": [
    "cd Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from skimage import transform as tf\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples created....\n"
     ]
    }
   ],
   "source": [
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "fntSizes = [20,21,22,23,24,25,26,27,28,29,30,31,32]\n",
    "\n",
    "def createsamples(text_pos,alpha,fnt,seq):\n",
    "    bgimage = Image.new('RGBA', (40,40), (255, 255, 255, 255))        \n",
    "    draw  = ImageDraw.Draw(bgimage)\n",
    "    draw.text(text_pos,alpha,font=fnt,fill=(0,0,0))\n",
    "    bgimage.save('samples/'+alpha+'_'+str(seq)+'.png')\n",
    "        \n",
    "for alpha in alphanum:\n",
    "    #print(str(seq))\n",
    "    seq = 1\n",
    "    for fntSize in fntSizes:\n",
    "        for i in range (50):\n",
    "            text_Pos = (1,1)                \n",
    "            fnt = ImageFont.truetype('arialbd.ttf', fntSize)\n",
    "            createsamples(text_Pos,alpha,fnt,seq)\n",
    "            seq = seq +1\n",
    "                \n",
    "print ('samples created....')\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images copied from sampels\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('samples/'):\n",
    "    img = cv2.imread('samples/'+filename)\n",
    "    cv2.imwrite('samplesBW/'+filename,img)\n",
    "print('images copied from sampels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/Desktop/Data Analytics/OCR\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images copied from CharSplitTrain\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in os.listdir('CharSplitTrain/1/'):\n",
    "    img = cv2.imread('CharSplitTrain/1/'+filename)\n",
    "    cv2.imwrite('Background/samplesBW/'+filename,img)\n",
    "    #print(filename)\n",
    "print('images copied from CharSplitTrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/Desktop/Data Analytics/OCR/Background\n"
     ]
    }
   ],
   "source": [
    "cd Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noice induced\n"
     ]
    }
   ],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    \n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        \n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy\n",
    "\n",
    "for filename in os.listdir('samplesBW/'):        \n",
    "    image = cv2.imread('samplesBW/'+filename)\n",
    "    #image = noisy('gauss',image)\n",
    "    #image = noisy('poisson',image)\n",
    "    image = cv2.blur(image,(2,2))\n",
    "    ##print(image)\n",
    "    cv2.imwrite('samplesBW/'+filename,image)\n",
    "    #image = noisy(image)\n",
    "    #print(filename)\n",
    "    #blendImage(image,'samplesBW/'+filename)\n",
    "    #cv2.imwrite('samplesBW/'+filename,image)\n",
    "\n",
    "print('noice induced')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reshaping\n",
      "number of files23401\n",
      "Reshaping Complete\n",
      "Starting to segregate Training and Validation sets\n",
      "[b'H' b'P' b'J' ..., b'X' b'L' b'8']\n",
      "Segregation Completed\n"
     ]
    }
   ],
   "source": [
    "print('start reshaping')\n",
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "noOfFiles = len([name for name in os.listdir('samplesBW/')])\n",
    "print('number of files'+str(noOfFiles))\n",
    "\n",
    "reshaped = np.empty([noOfFiles,1600])\n",
    "Y = np.chararray([noOfFiles,1]) \n",
    "j=0\n",
    "for filename in os.listdir('samplesBW/'):\n",
    "    image = io.imread('samplesBW/'+filename,'0')\n",
    "    reshaped[j] = image.reshape(1,1600)\n",
    "    Y[j] = filename[:1]\n",
    "    j = j+1\n",
    "    \n",
    "\n",
    "print('Reshaping Complete')\n",
    "print('Starting to segregate Training and Validation sets')\n",
    "Y = np.ravel(Y)\n",
    "print(Y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(reshaped,Y)\n",
    "\n",
    "\n",
    "print('Segregation Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to feature scaling\n",
      "Feature Scaling Completed\n",
      "Start training\n",
      "Training done...\n",
      "Now start predicting for the validation set\n",
      "Predictions done\n",
      "evaluate the results\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       b'0'       1.00      1.00      1.00       168\n",
      "       b'1'       0.99      1.00      0.99       159\n",
      "       b'2'       0.99      0.99      0.99       179\n",
      "       b'3'       1.00      1.00      1.00       153\n",
      "       b'4'       1.00      1.00      1.00       156\n",
      "       b'5'       1.00      0.99      1.00       183\n",
      "       b'6'       1.00      0.98      0.99       156\n",
      "       b'7'       1.00      1.00      1.00       164\n",
      "       b'8'       1.00      1.00      1.00       168\n",
      "       b'9'       0.98      0.99      0.99       169\n",
      "       b'A'       0.99      0.99      0.99       159\n",
      "       b'B'       1.00      0.99      1.00       157\n",
      "       b'C'       1.00      1.00      1.00       159\n",
      "       b'D'       1.00      0.99      1.00       176\n",
      "       b'E'       1.00      0.99      1.00       163\n",
      "       b'F'       1.00      0.99      1.00       156\n",
      "       b'G'       0.99      1.00      1.00       154\n",
      "       b'H'       0.99      0.99      0.99       153\n",
      "       b'I'       1.00      1.00      1.00       156\n",
      "       b'J'       1.00      0.99      1.00       154\n",
      "       b'K'       1.00      1.00      1.00       165\n",
      "       b'L'       1.00      1.00      1.00       159\n",
      "       b'M'       0.98      0.99      0.99       149\n",
      "       b'N'       0.99      0.99      0.99       161\n",
      "       b'O'       1.00      1.00      1.00       174\n",
      "       b'P'       1.00      0.99      1.00       160\n",
      "       b'Q'       0.99      1.00      1.00       155\n",
      "       b'R'       1.00      1.00      1.00       175\n",
      "       b'S'       0.99      0.99      0.99       165\n",
      "       b'T'       1.00      1.00      1.00       157\n",
      "       b'U'       0.99      1.00      1.00       154\n",
      "       b'V'       1.00      0.99      1.00       177\n",
      "       b'W'       0.99      1.00      1.00       152\n",
      "       b'X'       1.00      1.00      1.00       156\n",
      "       b'Y'       1.00      1.00      1.00       182\n",
      "       b'Z'       0.99      1.00      1.00       168\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('starting to feature scaling')\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "#scaler.fit(X_Train)\n",
    "#X_Train = scaler.transform(X_Train)\n",
    "#X_Test = scaler.transform(X_Test)\n",
    "\n",
    "print('Feature Scaling Completed')\n",
    "print('Start training')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(60,60,60,60),alpha=0.00001)\n",
    "mlp.fit(X_Train,Y_Train)\n",
    "\n",
    "\n",
    "print('Training done...')\n",
    "print('Now start predicting for the validation set')\n",
    "predictions = mlp.predict(X_Test)\n",
    "\n",
    "print('Predictions done')\n",
    "print('evaluate the results')\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(Y_Test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mlp,open('AlphabetRecognition.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images created...\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('Test/'):  \n",
    "    #BGImage = Image.open('defaultBG.png')\n",
    "    #img = Image.open('Test/'+filename)    \n",
    "    #BGImage.paste(img, (15,15))    \n",
    "    #BGImage.save('TestBW/'+filename)\n",
    "    \n",
    "    image = cv2.imread('Test/'+filename)\n",
    "    gray_masked = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, im_bw) = cv2.threshold(gray_masked, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    cv2.imwrite('TestBW/'+filename,im_bw)\n",
    "    #blendImage(image,'TestBW/'+filename)\n",
    "    \n",
    "print('Test images created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images created...\n"
     ]
    }
   ],
   "source": [
    "#Paste the BW image onto a standard 50X50 white background\n",
    "for filename in os.listdir('TestBW/'):\n",
    "    img = Image.open('TestBW/'+filename)\n",
    "    bgimage = Image.new('RGBA', (40,40), (255, 255, 255, 255))        \n",
    "    pos = (1,1)\n",
    "    bgimage.paste(img,pos)\n",
    "    bgimage.save('TestBW/'+filename)\n",
    "    \n",
    "    image = cv2.imread('TestBW/'+filename)\n",
    "    image = cv2.blur(image,(2,2))\n",
    "    cv2.imwrite('TestBW/'+filename,image)\n",
    "    \n",
    "print('Test images created...')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to reshape the test images\n",
      "reshaping done...\n",
      "start predicting\n",
      "[b'A' b'M' b'S' b'P' b'H' b'5' b'V' b'6' b'7' b'E']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       b'5'       1.00      1.00      1.00         1\n",
      "       b'6'       1.00      1.00      1.00         1\n",
      "       b'7'       1.00      1.00      1.00         1\n",
      "       b'9'       0.00      0.00      0.00         1\n",
      "       b'A'       1.00      1.00      1.00         1\n",
      "       b'E'       1.00      1.00      1.00         1\n",
      "       b'H'       0.00      0.00      0.00         0\n",
      "       b'K'       0.00      0.00      0.00         1\n",
      "       b'M'       0.00      0.00      0.00         0\n",
      "       b'P'       1.00      1.00      1.00         1\n",
      "       b'S'       1.00      1.00      1.00         1\n",
      "       b'V'       0.00      0.00      0.00         0\n",
      "       b'W'       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.70      0.70      0.70        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('starting to reshape the test images')\n",
    "pannumber = ['A','W','S','P','K','5','9','6','7','E']\n",
    "reshaped1 = np.empty([10,1600])\n",
    "Y1=np.chararray([len(pannumber),1])\n",
    "j=0\n",
    "for alpha in pannumber:\n",
    "    #for i in range (1,3):\n",
    "        filename = 'TestBW/'+alpha+'_1.PNG'\n",
    "        #print(filename)\n",
    "        image = io.imread(filename,'1')    \n",
    "        #print(image)\n",
    "        reshaped1[j] = image.reshape(1,1600)\n",
    "        Y1[j] = alpha\n",
    "        j = j+1\n",
    "\n",
    "Y1 = np.ravel(Y1)\n",
    "\n",
    "print('reshaping done...')\n",
    "print('start predicting')\n",
    "#X1_Test = scaler.transform(reshaped1)\n",
    "predictions = mlp.predict(reshaped1)\n",
    "print(predictions)\n",
    "print(classification_report(Y1,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'A' b'T' b'M' b'Y' b'M' b'5' b'T' b'E' b'7' b'E']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

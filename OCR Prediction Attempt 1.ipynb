{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detectLetters(image,kernelSize,rtvMode,approx):\n",
    "    boundRect = [None]\n",
    "    #image = cv2.imread(inputFilename)\n",
    "    \n",
    " \n",
    "    # convert the image to grayscale, blur it, and find edges\n",
    "    # in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "    # show the original image and the edge detected image\n",
    "    cv2.imwrite('originals/dltme1.png',edged)\n",
    "    print (\"STEP 1: Edge Detection\")\n",
    "\n",
    "    #Binary Dialation\n",
    "    kernelSize = (17,3)\n",
    "    element = cv2.getStructuringElement (cv2.MORPH_RECT, kernelSize )\n",
    "    img_threshold = cv2.morphologyEx(edged,cv2.MORPH_CLOSE,element)\n",
    "    cv2.imwrite('originals/dltme2.png',img_threshold)\n",
    "    print('Binary dialation done...')\n",
    "    \n",
    "    #Find Contours\n",
    "    im2,contours,hierarchy = cv2.findContours(img_threshold,rtvMode,approx)\n",
    "    contours_poly = [None]*len(contours)\n",
    "    for i in range(0,len(contours)):\n",
    "        if len(contours[i])>100:            \n",
    "            contours_poly[i]=(cv2.approxPolyDP(contours[i], 3, True))            \n",
    "            x,y,w,h = cv2.boundingRect(contours_poly[i])            \n",
    "            if w>h:\n",
    "                temp = x,y,w,h\n",
    "                boundRect.append(temp)\n",
    "    return boundRect\n",
    "\n",
    "def extractTextArea(inputFile,outputFile,kernelSize,rtvMode,approx):\n",
    "    #implementation    \n",
    "    img = cv2.imread(inputFile)\n",
    "    ratio = img.shape[0] / 500.0\n",
    "    orig = img.copy()\n",
    "    img = imutils.resize(img, height = 500)\n",
    "    letterBBoxes=detectLetters(img,kernelSize,rtvMode,approx)\n",
    "    for i in range(0,len(letterBBoxes)-1):\n",
    "        if letterBBoxes[i] != None:        \n",
    "            temp = letterBBoxes[i]\n",
    "            cv2.rectangle(orig,(temp[0],temp[1]),(temp[0]+temp[2],temp[1]+temp[3]),(0,255,0),3)\n",
    "            crop_image = img[temp[1]:temp[1]+temp[3], temp[0]:temp[0]+temp[2]]\n",
    "            filename = 'originals/TextArea/'+inputFile[10:-4]+'_'+str(i)+'.png'\n",
    "            #print(filename)            \n",
    "            cv2.imwrite(filename,crop_image)\n",
    "            #print('cropped image created')\n",
    "\n",
    "    cv2.imwrite(outputFile,img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n",
      "Binary dialation done...\n",
      "STEP 1: Edge Detection\n",
      "Binary dialation done...\n",
      "STEP 1: Edge Detection\n",
      "Binary dialation done...\n",
      "STEP 1: Edge Detection\n",
      "Binary dialation done...\n",
      "STEP 1: Edge Detection\n",
      "Binary dialation done...\n",
      "all done...\n"
     ]
    }
   ],
   "source": [
    "kernelSize = (17,3)\n",
    "extractTextArea('originals/Pancard.png','originals/Pancard_1.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "kernelSize = (17,3)\n",
    "extractTextArea('originals/Pancard_Web_1.png','originals/Pancard_Web_1_1.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "kernelSize = (17,3)\n",
    "extractTextArea('originals/Pancard_Web_2.png','originals/Pancard_Web_2_1.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "kernelSize = (17,3)\n",
    "extractTextArea('originals/Pancard_Web_3.png','originals/Pancard_Web_3_1.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "kernelSize = (17,3)\n",
    "extractTextArea('originals/Pancard_Web_4.png','originals/Pancard_Web_4_1.png',kernelSize,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "print('all done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images printed\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "def setImage(image):\n",
    "    gray_masked = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, im_bw) = cv2.threshold(gray_masked, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #print(im_bw.shape)\n",
    "    #Draw a white canvas\n",
    "    white_img = np.zeros((40,40), np.uint8)\n",
    "    white_img[:,:] = (0)\n",
    "    \n",
    "    #Paste the image onto the white canvas\n",
    "    x_offset=y_offset=1\n",
    "    white_img[y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = im_bw\n",
    "    \n",
    "    return white_img\n",
    "    \n",
    "def split(image):\n",
    "    image = image.reshape(1,1600)\n",
    "    predicted = loaded_model.predict(image)\n",
    "    if predicted == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "loaded_model = pickle.load(open('Model output/CharSplit.sav', 'rb'))\n",
    "org_img = cv2.imread('originals/TextArea/Pancard_10.png')\n",
    "r = 200.0 / org_img.shape[1]\n",
    "dim = (200, int(org_img.shape[0] * r))\n",
    " \n",
    "# perform the actual resizing of the image and show it\n",
    "resized = cv2.resize(org_img, dim, interpolation = cv2.INTER_AREA)\n",
    "#resized = org_img\n",
    "\n",
    "#print(org_image)\n",
    "(height, width,_) = resized.shape\n",
    "init_column = 0\n",
    "\n",
    "i=0\n",
    "j=1\n",
    "end_column = 14\n",
    "while (init_column < width):\n",
    "    i=i+1\n",
    "    \n",
    "    temp_image = resized[:,init_column:init_column+end_column+i,:]\n",
    "    \n",
    "    if split(setImage(temp_image)):                \n",
    "        cv2.imwrite('dltme_'+str(j)+'_m.png',temp_image)\n",
    "        #cv2.imwrite('dltme_'+str(j)+'_a.png',setImage(temp_image))\n",
    "        j=j+1\n",
    "        init_column = init_column+end_column+i\n",
    "        i=0\n",
    "    elif (init_column+end_column+i >= 40):\n",
    "        init_column = init_column+1\n",
    "        i=0\n",
    "    elif (init_column+end_column+i >= width):\n",
    "        init_column = width\n",
    "    \n",
    "print('images printed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

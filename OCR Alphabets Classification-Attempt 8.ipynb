{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from skimage import transform as tf\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples created....\n"
     ]
    }
   ],
   "source": [
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "fntSizes = [20,21,22,23,24,25,26,27,28,29,30,31,32]\n",
    "\n",
    "def createsamples(text_pos,alpha,fnt,seq,fntSize):\n",
    "    if alpha =='M' or alpha == 'W':\n",
    "        bgimage = Image.new('RGBA', (fntSize,fntSize), (255, 255, 255, 255))     \n",
    "    elif alpha =='I':\n",
    "        bgimage = Image.new('RGBA', (fntSize-10,fntSize), (255, 255, 255, 255))             \n",
    "    elif alpha in ('0','1','2','3','4','5','6','7','8','9'):\n",
    "        bgimage = Image.new('RGBA', (fntSize-3,fntSize), (255, 255, 255, 255))             \n",
    "    else:\n",
    "        bgimage = Image.new('RGBA', (fntSize-2,fntSize), (255, 255, 255, 255)) \n",
    "        \n",
    "    draw  = ImageDraw.Draw(bgimage)\n",
    "    draw.text(text_pos,alpha,font=fnt,fill=(0,0,0))\n",
    "    bgimage.save('Background/samples2/'+alpha+'_'+str(seq)+'.png')\n",
    "    image = cv2.imread('Background/samples2/'+alpha+'_'+str(seq)+'.png')\n",
    "    image = imutils.resize(image,height=20)\n",
    "    white_img = np.zeros((40,40,3), np.uint8)\n",
    "    white_img[:,:] = (255,255,255)\n",
    "    #Paste the image onto the white canvas\n",
    "    x_offset=y_offset=1    \n",
    "    white_img[y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = image\n",
    "    cv2.imwrite('Background/samples2/'+alpha+'_'+str(seq)+'.png',white_img)\n",
    "        \n",
    "for alpha in alphanum:\n",
    "    #print(str(seq))\n",
    "    seq = 1\n",
    "    for fntSize in fntSizes:\n",
    "        #for i in range (50):\n",
    "        text_Pos = (1,1)                \n",
    "        fnt = ImageFont.truetype('Background/arialbd.ttf', fntSize)\n",
    "        createsamples(text_Pos,alpha,fnt,seq,fntSize)\n",
    "        seq = seq +1\n",
    "                \n",
    "print ('samples created....')\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images copied from samples2\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('Background/samples2/'):\n",
    "    img = cv2.imread('Background/samples2/'+filename)\n",
    "    cv2.imwrite('Background/samplesBW2/'+filename,img)\n",
    "print('images copied from samples2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images copied from CharSplitTrain\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in os.listdir('CharSplitTrain/1/'):\n",
    "    image = cv2.imread('CharSplitTrain/1/'+filename)\n",
    "    #image = imutils.resize(image,height=20)\n",
    "    #white_img = np.zeros((40,40,3), np.uint8)\n",
    "    #white_img[:,:] = (255,255,255)\n",
    "    #Paste the image onto the white canvas\n",
    "    #x_offset=y_offset=1    \n",
    "    #white_img[y_offset:y_offset+image.shape[0], x_offset:x_offset+image.shape[1]] = image\n",
    "    cv2.imwrite('Background/samplesBW2/'+filename,image)\n",
    "    #print(filename)\n",
    "print('images copied from CharSplitTrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noice induced\n"
     ]
    }
   ],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    \n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        \n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy\n",
    "\n",
    "for filename in os.listdir('Background/samplesBW2/'):        \n",
    "    image = cv2.imread('Background/samplesBW2/'+filename)\n",
    "    #image = noisy('gauss',image)\n",
    "    #image = noisy('poisson',image)\n",
    "    image = cv2.blur(image,(2,2))\n",
    "    ##print(image)\n",
    "    cv2.imwrite('Background/samplesBW2/'+filename,image)\n",
    "    #image = noisy(image)\n",
    "    #print(filename)\n",
    "    #blendImage(image,'samplesBW/'+filename)\n",
    "    #cv2.imwrite('samplesBW/'+filename,image)\n",
    "\n",
    "print('noice induced')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reshaping\n",
      "number of files1144\n",
      "Reshaping Complete\n",
      "Starting to segregate Training and Validation sets\n",
      "Segregation Completed\n"
     ]
    }
   ],
   "source": [
    "print('start reshaping')\n",
    "alphanum = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9']\n",
    "noOfFiles = len([name for name in os.listdir('Background/samplesBW2/')])\n",
    "print('number of files'+str(noOfFiles))\n",
    "\n",
    "reshaped = np.empty([noOfFiles,1600])\n",
    "Y = np.chararray([noOfFiles,1]) \n",
    "j=0\n",
    "for filename in os.listdir('Background/samplesBW2/'):\n",
    "    image = io.imread('Background/samplesBW2/'+filename,'0')\n",
    "    reshaped[j] = image.reshape(1,1600)\n",
    "    Y[j] = filename[:1]\n",
    "    j = j+1\n",
    "    \n",
    "\n",
    "print('Reshaping Complete')\n",
    "print('Starting to segregate Training and Validation sets')\n",
    "Y = np.ravel(Y)\n",
    "#print(Y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(reshaped,Y)\n",
    "\n",
    "\n",
    "print('Segregation Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to feature scaling\n",
      "Feature Scaling Completed\n",
      "Start training\n",
      "Training done...\n",
      "Now start predicting for the validation set\n",
      "Predictions done\n",
      "evaluate the results\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       b'0'       1.00      0.75      0.86         8\n",
      "       b'1'       1.00      0.83      0.91         6\n",
      "       b'2'       1.00      1.00      1.00         5\n",
      "       b'3'       1.00      1.00      1.00         2\n",
      "       b'4'       1.00      1.00      1.00         6\n",
      "       b'5'       1.00      0.88      0.93         8\n",
      "       b'6'       0.90      1.00      0.95         9\n",
      "       b'7'       1.00      1.00      1.00         3\n",
      "       b'8'       1.00      1.00      1.00         3\n",
      "       b'9'       1.00      0.78      0.88         9\n",
      "       b'A'       1.00      0.91      0.95        32\n",
      "       b'C'       1.00      1.00      1.00         4\n",
      "       b'D'       1.00      1.00      1.00        13\n",
      "       b'E'       1.00      1.00      1.00        21\n",
      "       b'F'       1.00      1.00      1.00         5\n",
      "       b'G'       0.75      1.00      0.86         6\n",
      "       b'H'       1.00      1.00      1.00         9\n",
      "       b'I'       1.00      1.00      1.00         9\n",
      "       b'J'       1.00      1.00      1.00         3\n",
      "       b'K'       1.00      1.00      1.00         8\n",
      "       b'L'       1.00      1.00      1.00         2\n",
      "       b'M'       1.00      0.89      0.94        18\n",
      "       b'N'       1.00      1.00      1.00        21\n",
      "       b'O'       1.00      1.00      1.00         2\n",
      "       b'P'       1.00      1.00      1.00         8\n",
      "       b'Q'       1.00      1.00      1.00         2\n",
      "       b'R'       1.00      1.00      1.00         7\n",
      "       b'S'       0.85      1.00      0.92        11\n",
      "       b'T'       0.90      1.00      0.95         9\n",
      "       b'U'       1.00      1.00      1.00         8\n",
      "       b'V'       0.79      1.00      0.88        11\n",
      "       b'W'       0.67      1.00      0.80         4\n",
      "       b'X'       1.00      1.00      1.00         3\n",
      "       b'Y'       1.00      1.00      1.00         7\n",
      "       b'Z'       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       0.97      0.96      0.96       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('starting to feature scaling')\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "#scaler.fit(X_Train)\n",
    "#X_Train = scaler.transform(X_Train)\n",
    "#X_Test = scaler.transform(X_Test)\n",
    "\n",
    "print('Feature Scaling Completed')\n",
    "print('Start training')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(340,340,340),alpha=0.0001)\n",
    "mlp.fit(X_Train,Y_Train)\n",
    "\n",
    "\n",
    "print('Training done...')\n",
    "print('Now start predicting for the validation set')\n",
    "predictions = mlp.predict(X_Test)\n",
    "\n",
    "print('Predictions done')\n",
    "print('evaluate the results')\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(Y_Test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mlp,open('Model output/AlphabetRecognition.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images created...\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('Background/Test/'):  \n",
    "    #BGImage = Image.open('defaultBG.png')\n",
    "    #img = Image.open('Test/'+filename)    \n",
    "    #BGImage.paste(img, (15,15))    \n",
    "    #BGImage.save('TestBW/'+filename)\n",
    "    \n",
    "    image = cv2.imread('Background/Test/'+filename)\n",
    "    gray_masked = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, im_bw) = cv2.threshold(gray_masked, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    im_bw = imutils.resize(im_bw,height = 20)\n",
    "    \n",
    "    cv2.imwrite('Background/TestBW/'+filename,im_bw)\n",
    "    #blendImage(image,'TestBW/'+filename)\n",
    "    \n",
    "print('Test images created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images created...\n"
     ]
    }
   ],
   "source": [
    "#Paste the BW image onto a standard 50X50 white background\n",
    "for filename in os.listdir('Background/TestBW/'):\n",
    "    img = Image.open('Background/TestBW/'+filename)\n",
    "    bgimage = Image.new('RGBA', (40,40), (255, 255, 255, 255))        \n",
    "    pos = (1,1)\n",
    "    bgimage.paste(img,pos)\n",
    "    bgimage.save('Background/TestBW/'+filename)\n",
    "    \n",
    "    image = cv2.imread('Background/TestBW/'+filename)\n",
    "    image = cv2.blur(image,(5,5))\n",
    "    cv2.imwrite('Background/TestBW/'+filename,image)\n",
    "    \n",
    "print('Test images created...')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to reshape the test images\n",
      "reshaping done...\n",
      "start predicting\n",
      "[b'K' b'V' b'G' b'J' b'K' b'9' b'S' b'6' b'7' b'E']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       b'5'       0.00      0.00      0.00         1\n",
      "       b'6'       1.00      1.00      1.00         1\n",
      "       b'7'       1.00      1.00      1.00         1\n",
      "       b'9'       0.00      0.00      0.00         1\n",
      "       b'A'       0.00      0.00      0.00         1\n",
      "       b'E'       1.00      1.00      1.00         1\n",
      "       b'G'       0.00      0.00      0.00         0\n",
      "       b'J'       0.00      0.00      0.00         0\n",
      "       b'K'       0.50      1.00      0.67         1\n",
      "       b'P'       0.00      0.00      0.00         1\n",
      "       b'S'       0.00      0.00      0.00         1\n",
      "       b'V'       0.00      0.00      0.00         0\n",
      "       b'W'       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.35      0.40      0.37        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kunjithapathams/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('starting to reshape the test images')\n",
    "pannumber = ['A','W','S','P','K','5','9','6','7','E']\n",
    "reshaped1 = np.empty([10,1600])\n",
    "Y1=np.chararray([len(pannumber),1])\n",
    "j=0\n",
    "for alpha in pannumber:\n",
    "    #for i in range (1,3):\n",
    "        filename = 'Background/TestBW/'+alpha+'_1.PNG'\n",
    "        #print(filename)\n",
    "        image = io.imread(filename,'1')    \n",
    "        #print(image)\n",
    "        reshaped1[j] = image.reshape(1,1600)\n",
    "        Y1[j] = alpha\n",
    "        j = j+1\n",
    "\n",
    "Y1 = np.ravel(Y1)\n",
    "\n",
    "print('reshaping done...')\n",
    "print('start predicting')\n",
    "#X1_Test = scaler.transform(reshaped1)\n",
    "predictions = mlp.predict(reshaped1)\n",
    "print(predictions)\n",
    "print(classification_report(Y1,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'A' b'T' b'M' b'Y' b'M' b'5' b'T' b'E' b'7' b'E']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
